# Implementing Attacks on Machine Learning Models to Evade and Deceive Intrusion Detection Systems

Author: Jordan Wallingsford
George Mason University

## Overview

This is the code involved in my research for the paper I wrote for my capstone, titled the above. The statement of purpose for the paper is below:

### Statement of Purpose

The goal of this paper will be to showcase some of the most common vulnerabilities found in artificial intelligence driven intrusion detection systems and detail the various ways these vulnerabilities can be used to evade detection and weaken network security. It will introduce multiple different machine learning models that are designed similarly to enterprise machine learning intrusion detection models as well as specially crafted data manipulation attacks against these specific models. It will utilize previous research to increase awareness on the topic, as well as lay a foundation for the research to be done. The usage of previous research will allow for a more fine-tuned model and attack methods to manipulate the said model.

### Contents

There are 2 .ipynb files, one for the development and testing of a long-short-term memory neural network and the other for a multi-layer perceptron neural network. In `data` there are the datasets used for the training. 

## Contact

If you have any questions, reach out at jwalling@gmu.edu
