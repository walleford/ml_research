{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ci-jxd1ZC99Z"
      },
      "source": [
        "This is the portion where we import all the necessary modules and connect to our google drive to access the datasets. We import the datasets and convert them to Pandas dataframes, and we define our global functions for scaling and one-hot encoding our data.\n",
        "\n",
        "I am going to use this function I found to downsize the data types in the dataset to reduce the memory usage. https://www.kaggle.com/code/arjanso/reducing-dataframe-memory-size-by-65"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2lH_FwQCS2U",
        "outputId": "8c983a2f-9058-4b08-f568-c80815e33d0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /datasets/\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount(\n",
        "    '/datasets/'\n",
        ")\n",
        "from sklearn import preprocessing\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import imblearn\n",
        "import pandas as pd\n",
        "import os\n",
        "np.random.seed(0)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "unsw_testing_df = pd.read_csv('/datasets/MyDrive/datasets/UNSW_NB15_testing-set.csv')\n",
        "unsw_train_df = pd.read_csv('/datasets/MyDrive/datasets/UNSW_NB15_training-set.csv')\n",
        "cicids_files = ['/datasets/MyDrive/datasets/Wednesday-workingHours.pcap_ISCX.csv',\n",
        "                '/datasets/MyDrive/datasets/Tuesday-WorkingHours.pcap_ISCX.csv',\n",
        "                '/datasets/MyDrive/datasets/Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
        "                '/datasets/MyDrive/datasets/Monday-WorkingHours.pcap_ISCX.csv'\n",
        "                ]\n",
        "cicids_df = pd.concat((pd.read_csv(f) for f in cicids_files), ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper Functions"
      ],
      "metadata": {
        "id": "2yFYty6DsyAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def one_hot(df):\n",
        "    categorical_cols = ['proto','service','state']\n",
        "    for col in categorical_cols:\n",
        "        dummies = pd.get_dummies(df[col].astype({col: 'str'}),prefix=col, dtype=int)\n",
        "        df = pd.concat([df,dummies],axis=1)\n",
        "        df = df.drop(col,axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "def scaling(df, df_columns):\n",
        "    \"\"\"\n",
        "        This will be used to scale the data in the df to [0,1].\n",
        "\n",
        "        Will be done using the Min-max feature scaling technique\n",
        "        to bring all the values into the range [0,1]\n",
        "    \"\"\"\n",
        "    new_normalized_df = df.copy()\n",
        "    for column in df_columns:\n",
        "        max_value = df[column].max()\n",
        "        min_value = df[column].min()\n",
        "        if max_value > min_value:\n",
        "            new_normalized_df[column] = (new_normalized_df[column] - min_value) / (max_value - min_value)\n",
        "\n",
        "    return new_normalized_df\n",
        "\n",
        "def reduce_mem_usage(props):\n",
        "    start_mem_usg = props.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
        "    NAlist = [] # Keeps track of columns that have missing values filled in.\n",
        "    for col in props.columns:\n",
        "        if props[col].dtype != object:  # Exclude strings\n",
        "\n",
        "            # make variables for Int, max and min\n",
        "            IsInt = False\n",
        "            mx = props[col].max()\n",
        "            mn = props[col].min()\n",
        "\n",
        "            # Integer does not support NA, therefore, NA needs to be filled\n",
        "            if not np.isfinite(props[col]).all():\n",
        "                NAlist.append(col)\n",
        "                props[col].fillna(mn-1,inplace=True)\n",
        "\n",
        "            # test if column can be converted to an integer\n",
        "            asint = props[col].fillna(0).replace([np.inf, -np.inf], 0).astype(np.int64) # Replace inf values with 0\n",
        "            result = (props[col] - asint)\n",
        "            result = result.sum()\n",
        "            if result > -0.01 and result < 0.01:\n",
        "                IsInt = True\n",
        "\n",
        "\n",
        "            # Make Integer/unsigned Integer datatypes\n",
        "            if IsInt:\n",
        "                if mn >= 0:\n",
        "                    if mx < 255:\n",
        "                        props[col] = props[col].astype(np.uint8)\n",
        "                    elif mx < 65535:\n",
        "                        props[col] = props[col].astype(np.uint16)\n",
        "                    elif mx < 4294967295:\n",
        "                        props[col] = props[col].astype(np.uint32)\n",
        "                    else:\n",
        "                        props[col] = props[col].astype(np.uint64)\n",
        "                else:\n",
        "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
        "                        props[col] = props[col].astype(np.int8)\n",
        "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
        "                        props[col] = props[col].astype(np.int16)\n",
        "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
        "                        props[col] = props[col].astype(np.int32)\n",
        "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
        "                        props[col] = props[col].astype(np.int64)\n",
        "\n",
        "            # Make float datatypes 32 bit\n",
        "            else:\n",
        "                props[col] = props[col].astype(np.float32)\n",
        "\n",
        "    # Print final result\n",
        "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
        "    mem_usg = props.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
        "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
        "    return props, NAlist\n",
        "\n",
        "loss_obj = keras.losses.BinaryCrossentropy()\n",
        "def create_adversarial_examples(input, labels, model):\n",
        "  with tf.GradientTape() as tape:\n",
        "    tape.watch(input)\n",
        "    predictions = model(input)\n",
        "    loss = loss_obj(labels, predictions)\n",
        "  gradient = tape.gradient(loss, input)\n",
        "  signed_grad = tf.sign(gradient)\n",
        "  return signed_grad\n",
        "\n",
        "def calculate_metrics(lables, predictions):\n",
        "  true_lables = lables.values.flatten()\n",
        "  predicted_labels = predictions.flatten()\n",
        "\n",
        "  accuracy = accuracy_score(true_lables, predicted_labels)\n",
        "  precision = precision_score(true_lables, predicted_labels)\n",
        "  recall = recall_score(true_lables, predicted_labels)\n",
        "  f1 = f1_score(true_lables, predicted_labels)\n",
        "  print(f'Accuracy: {accuracy:.2f}')\n",
        "  print(f'Precision: {precision:.2f}')\n",
        "  print(f'Recall: {recall:.2f}')\n",
        "  print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "\n",
        "def make_predictions(model, data, labels):\n",
        "    predictions = model.predict(data)\n",
        "    binary_predictions = np.where(predictions >= 0.5, 1, 0)\n",
        "    return binary_predictions\n"
      ],
      "metadata": {
        "id": "9wG1sl6mskFk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY5zWcRoDKeZ"
      },
      "source": [
        "This is the cleaning we do for the UNSW dataset. We have to reduce the amount of unique values in each feature to make training more efficient, we then remove the attack categories and one-hot encode every feature to bring it from a categorical to a numerical feature. Afterwards, we one hot encode every feature to bring it into the range of [0,1] which improves accuracy in training/testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XDdK-keXCc7P",
        "outputId": "8a4d548b-025b-42ec-98ce-ef320fdd2f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         proto service   state attack_cat\n",
            "count   175341  175341  175341     175341\n",
            "unique     133      13       9         10\n",
            "top        tcp       -     INT     Normal\n",
            "freq     79946   94168   82275      56000\n",
            "Memory usage of properties dataframe is : 58.860931396484375  MB\n",
            "___MEMORY USAGE AFTER COMPLETION:___\n",
            "Memory usage is:  20.902398109436035  MB\n",
            "This is  35.51149737784218 % of the initial size\n",
            "Fully duplicate rows to drop: 0\n",
            "UNSW Dataframe Shape After cleaning: (175341, 44)\n",
            "UNSW Testing Sample Shape: (43836, 1, 58)\n",
            "UNSW Training Sample Shape: (84058, 1, 58)\n"
          ]
        }
      ],
      "source": [
        "df_cat = unsw_train_df.select_dtypes(exclude=[np.number])\n",
        "print(df_cat.describe(include='all'))\n",
        "DEBUG = 0\n",
        "## reducing the amount of uniques in each feature\n",
        "for feature in df_cat.columns:\n",
        "    if DEBUG == 1:\n",
        "        print(feature)\n",
        "        print('nunique = '+str(df_cat[feature].nunique()))\n",
        "        print(df_cat[feature].nunique()>7)\n",
        "        print(sum(unsw_train_df[feature].isin(unsw_train_df[feature].value_counts().head().index)))\n",
        "        print('----------------------------------------------------')\n",
        "\n",
        "    if df_cat[feature].nunique()>8:\n",
        "        unsw_train_df[feature] = np.where(unsw_train_df[feature].isin(unsw_train_df[feature].value_counts().head().index), unsw_train_df[feature], 'Combined')\n",
        "# taking out the attack category\n",
        "unsw_attack_cat = unsw_train_df.pop('attack_cat')\n",
        "\n",
        "# going to reduce the amount of memory the dataset takes\n",
        "unsw_train_df.columns = unsw_train_df.columns.str.strip()\n",
        "unsw_df, NAList = reduce_mem_usage(unsw_train_df)\n",
        "# replacing infinity, and neg infinity values with NaN then dropping them\n",
        "unsw_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "unsw_df.dropna(inplace=True)\n",
        "# dropping duplicates\n",
        "print(f\"Fully duplicate rows to drop: {unsw_df.duplicated().sum()}\")\n",
        "unsw_df.drop_duplicates(inplace=True)\n",
        "unsw_df.reset_index(drop=True, inplace=True)\n",
        "# one hot encoding the entire dataframe\n",
        "unsw_e_df = one_hot(unsw_df)\n",
        "# scaling the dataframe using our scaling() function\n",
        "unsw_s_df = scaling(unsw_e_df, unsw_e_df.columns)\n",
        "# dropping the label column in order to undersample\n",
        "unsw_unlabled_df = unsw_s_df.drop('label', axis=1)\n",
        "# setting the labels to a var so we don't lose them\n",
        "lables = unsw_s_df['label']\n",
        "print(f\"UNSW Dataframe Shape After cleaning: {unsw_df.shape}\")\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "# splitting the dataframe into testing and training with a 75/25 split\n",
        "unsw_unlabled_df_train, unsw_unlabeled_df_test, unsw_lables_train, unsw_lables_test = train_test_split(unsw_unlabled_df, lables, train_size=0.75, random_state=42)\n",
        "# combining them for kfold cross validation\n",
        "inputs = pd.concat([unsw_unlabeled_df_test, unsw_unlabled_df_train])\n",
        "targets = pd.concat([unsw_lables_test, unsw_lables_train])\n",
        "# under-sampling the dataset using SMOTE\n",
        "under = RandomUnderSampler(sampling_strategy=1)\n",
        "unsw_train_smote, unsw_label_train_smote = under.fit_resample(unsw_unlabled_df_train, unsw_lables_train)\n",
        "# adding the labels back to the dataframe\n",
        "unsw_train_df_smote = pd.concat([unsw_train_smote, unsw_label_train_smote], axis=1)\n",
        "# converting to a numpy array so we can reshape the input for our models\n",
        "unsw_nump_train = unsw_train_smote.to_numpy()\n",
        "unsw_nump_test = unsw_unlabeled_df_test.to_numpy()\n",
        "unsw_train = unsw_nump_train.reshape(unsw_nump_train.shape[0], 1, unsw_nump_train.shape[1])\n",
        "unsw_test = unsw_nump_test.reshape(unsw_nump_test.shape[0], 1, unsw_nump_test.shape[1])\n",
        "print(f\"UNSW Testing Sample Shape: {unsw_test.shape}\")\n",
        "print(f\"UNSW Training Sample Shape: {unsw_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rafxjRfDoiZ"
      },
      "source": [
        "This is the data cleaning we have to do for the CICIDS dataset. To begin we convert the Label feature into a numerical column with 0 being the benign label and 1 being the malicious label and adding those values to a new column: `mal_or_not`. We then remove the Label feature and scale the data for the entire set. We do our train/test split with a 75/25 ratio of data for training and testing. Then we convert to a numpy array so we can accurately gauge the shape of the dataset to pass to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r526PdRuCf3N",
        "outputId": "ec482b06-3228-4be8-c329-025b69546f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CICIDS Dataframe Shape Before: (1859563, 79)\n",
            "Memory usage of properties dataframe is : 1092.4252853393555  MB\n",
            "___MEMORY USAGE AFTER COMPLETION:___\n",
            "Memory usage is:  425.6203155517578  MB\n",
            "This is  38.96104578168395 % of the initial size\n",
            "fully duplicate rows to remove: 300645\n",
            "CICIDS Dataframe Shape After cleaning: (1556798, 77)\n",
            "CICIDS Testing Sample Shape: (389200, 1, 76)\n",
            "CICIDS Training Sample Shape: (306398, 1, 76)\n"
          ]
        }
      ],
      "source": [
        "print(f\"CICIDS Dataframe Shape Before: {cicids_df.shape}\")\n",
        "cicids_df.loc[cicids_df[' Label'] != \"BENIGN\", 'mal_or_not'] = 1\n",
        "cicids_df.loc[cicids_df[' Label'] == \"BENIGN\", 'mal_or_not'] = 0\n",
        "# pop the label off, then scale as it is a categorical column\n",
        "attack_labels = cicids_df.pop(\" Label\")\n",
        "drop_columns = [ # this list includes all spellings across CIC NIDS datasets\n",
        "    \"Flow ID\",\n",
        "    'Fwd Header Length.1',\n",
        "    \"Source IP\", \"Src IP\",\n",
        "    \"Source Port\", \"Src Port\",\n",
        "    \"Destination IP\", \"Dst IP\",\n",
        "    \"Destination Port\", \"Dst Port\",\n",
        "    \"Timestamp\",\n",
        "]\n",
        "temp = cicids_df\n",
        "temp.columns = temp.columns.str.strip() # deleting the trailing whitespaces if there are any\n",
        "temp.drop(columns=drop_columns, inplace=True, errors='ignore')\n",
        "temp_df, NAList = reduce_mem_usage(temp)\n",
        "temp_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "temp_df.dropna(inplace=True)\n",
        "print(f\"fully duplicate rows to remove: {temp_df.duplicated().sum()}\")\n",
        "temp_df.drop_duplicates(inplace=True)\n",
        "temp_df.reset_index(drop=True, inplace=True)\n",
        "cicids_df = temp_df\n",
        "# scaling the dataframe using our scaling() function\n",
        "cicids_s_df = scaling(cicids_df, cicids_df.columns)\n",
        "# dropping the label column in order to undersample\n",
        "cicids_unlabled_df = cicids_s_df.drop('mal_or_not', axis=1)\n",
        "# setting the labels to a var so we don't lose them\n",
        "lables = cicids_s_df['mal_or_not']\n",
        "print(f\"CICIDS Dataframe Shape After cleaning: {cicids_df.shape}\")\n",
        "# splitting the dataframe into testing and training with a 75/25 split\n",
        "cicids_unlabled_df_train, cicids_unlabeled_df_test, cicids_lables_train, cicids_lables_test = train_test_split(cicids_unlabled_df, lables, train_size=0.75, random_state=42)\n",
        "# under-sampling the dataset using SMOTE\n",
        "under = RandomUnderSampler(sampling_strategy=1)\n",
        "cicids_train_smote, cicids_label_train_smote = under.fit_resample(cicids_unlabled_df_train, cicids_lables_train)\n",
        "# adding the labels back to the dataframe\n",
        "cicids_train_df_smote = pd.concat([cicids_train_smote, cicids_label_train_smote], axis=1)\n",
        "# converting to a numpy array so we can reshape the input for our models\n",
        "cicids_nump_train = cicids_train_smote.to_numpy()\n",
        "cicids_nump_test = cicids_unlabeled_df_test.to_numpy()\n",
        "cicids_train = cicids_nump_train.reshape(cicids_nump_train.shape[0], 1, cicids_nump_train.shape[1])\n",
        "cicids_test = cicids_nump_test.reshape(cicids_nump_test.shape[0], 1, cicids_nump_test.shape[1])\n",
        "print(f\"CICIDS Testing Sample Shape: {cicids_test.shape}\")\n",
        "print(f\"CICIDS Training Sample Shape: {cicids_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCawYlQTEFWD"
      },
      "source": [
        "This is our CICIDS model using the LSTM architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Grzb6zWlCxOL"
      },
      "outputs": [],
      "source": [
        "cicids_model = keras.Sequential([\n",
        "    keras.layers.LSTM(units=256, input_shape=(cicids_train.shape[1], cicids_train.shape[2]), return_sequences=True),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.LSTM(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VN1odapLCx1l"
      },
      "outputs": [],
      "source": [
        "cicids_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0TWorMLCyFK",
        "outputId": "70bea07b-e6b4-495e-ff4c-868f016778c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7660/7660 [==============================] - 60s 8ms/step - loss: 0.1317 - accuracy: 0.9472 - val_loss: 0.1314 - val_accuracy: 0.9281\n",
            "Epoch 2/10\n",
            "7660/7660 [==============================] - 58s 8ms/step - loss: 0.0926 - accuracy: 0.9629 - val_loss: 0.1173 - val_accuracy: 0.9294\n",
            "Epoch 3/10\n",
            "7660/7660 [==============================] - 58s 8ms/step - loss: 0.0822 - accuracy: 0.9654 - val_loss: 0.1025 - val_accuracy: 0.9311\n",
            "Epoch 4/10\n",
            "7660/7660 [==============================] - 58s 8ms/step - loss: 0.0741 - accuracy: 0.9673 - val_loss: 0.0713 - val_accuracy: 0.9330\n",
            "Epoch 5/10\n",
            "7660/7660 [==============================] - 56s 7ms/step - loss: 0.0653 - accuracy: 0.9712 - val_loss: 0.0682 - val_accuracy: 0.9845\n",
            "Epoch 6/10\n",
            "7660/7660 [==============================] - 57s 7ms/step - loss: 0.0607 - accuracy: 0.9735 - val_loss: 0.0710 - val_accuracy: 0.9914\n",
            "Epoch 7/10\n",
            "7660/7660 [==============================] - 58s 8ms/step - loss: 0.0560 - accuracy: 0.9751 - val_loss: 0.0655 - val_accuracy: 0.9921\n",
            "Epoch 8/10\n",
            "7660/7660 [==============================] - 56s 7ms/step - loss: 0.0541 - accuracy: 0.9761 - val_loss: 0.0665 - val_accuracy: 0.9916\n",
            "Epoch 9/10\n",
            "7660/7660 [==============================] - 56s 7ms/step - loss: 0.0525 - accuracy: 0.9765 - val_loss: 0.0537 - val_accuracy: 0.9941\n",
            "Epoch 10/10\n",
            "7660/7660 [==============================] - 56s 7ms/step - loss: 0.0509 - accuracy: 0.9772 - val_loss: 0.0600 - val_accuracy: 0.9926\n"
          ]
        }
      ],
      "source": [
        "cicids_results = cicids_model.fit(cicids_train, cicids_label_train_smote, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_preds = make_predictions(cicids_model, cicids_test, cicids_lables_test)\n",
        "calculate_metrics(cicids_lables_test, clean_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KylLjcAP3w81",
        "outputId": "77769a5e-4359-4949-ec82-2dacabd6fdbc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12163/12163 [==============================] - 33s 3ms/step\n",
            "Accuracy: 0.98\n",
            "Precision: 0.85\n",
            "Recall: 0.99\n",
            "F1 Score: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj59UZyJEJeL"
      },
      "source": [
        "This is our UNSW Model using the LSTM architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ih20HQV8ENw_"
      },
      "outputs": [],
      "source": [
        "unsw_model = keras.Sequential([\n",
        "    keras.layers.LSTM(units=256, input_shape=(unsw_train.shape[1], unsw_train.shape[2]), return_sequences=True),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.LSTM(128, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oqV2P6dzyuMa"
      },
      "outputs": [],
      "source": [
        "unsw_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY-zIYRqyxAA",
        "outputId": "cbcdeee9-1f14-47d8-c280-5e894fd45842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2102/2102 [==============================] - 18s 8ms/step - loss: 0.1572 - accuracy: 0.9274 - val_loss: 0.1943 - val_accuracy: 0.8915\n",
            "Epoch 2/10\n",
            "2102/2102 [==============================] - 15s 7ms/step - loss: 0.1268 - accuracy: 0.9410 - val_loss: 0.1604 - val_accuracy: 0.9281\n",
            "Epoch 3/10\n",
            "2102/2102 [==============================] - 16s 8ms/step - loss: 0.1213 - accuracy: 0.9452 - val_loss: 0.1453 - val_accuracy: 0.9223\n",
            "Epoch 4/10\n",
            "2102/2102 [==============================] - 16s 8ms/step - loss: 0.1144 - accuracy: 0.9486 - val_loss: 0.1181 - val_accuracy: 0.9319\n",
            "Epoch 5/10\n",
            "2102/2102 [==============================] - 16s 8ms/step - loss: 0.1072 - accuracy: 0.9522 - val_loss: 0.1284 - val_accuracy: 0.9372\n",
            "Epoch 6/10\n",
            "2102/2102 [==============================] - 16s 8ms/step - loss: 0.1038 - accuracy: 0.9533 - val_loss: 0.1422 - val_accuracy: 0.9116\n",
            "Epoch 7/10\n",
            "2102/2102 [==============================] - 16s 7ms/step - loss: 0.0986 - accuracy: 0.9556 - val_loss: 0.1039 - val_accuracy: 0.9410\n",
            "Epoch 8/10\n",
            "2102/2102 [==============================] - 16s 7ms/step - loss: 0.0957 - accuracy: 0.9574 - val_loss: 0.1209 - val_accuracy: 0.9287\n",
            "Epoch 9/10\n",
            "2102/2102 [==============================] - 16s 7ms/step - loss: 0.0937 - accuracy: 0.9575 - val_loss: 0.1178 - val_accuracy: 0.9318\n",
            "Epoch 10/10\n",
            "2102/2102 [==============================] - 16s 7ms/step - loss: 0.0909 - accuracy: 0.9592 - val_loss: 0.1126 - val_accuracy: 0.9283\n"
          ]
        }
      ],
      "source": [
        "unsw_results = unsw_model.fit(unsw_train, unsw_label_train_smote, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unsw_clean_preds = make_predictions(unsw_model, unsw_test, unsw_lables_test)\n",
        "calculate_metrics(unsw_lables_test, unsw_clean_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o3-fbEc323U",
        "outputId": "c507c31b-0cfb-4d3f-d9d1-5fbce6d3826a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1370/1370 [==============================] - 4s 3ms/step\n",
            "Accuracy: 0.95\n",
            "Precision: 0.99\n",
            "Recall: 0.93\n",
            "F1 Score: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdTIBVG_gZNP"
      },
      "source": [
        "Generating the adversarial examples\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CICIDS"
      ],
      "metadata": {
        "id": "Nxk-Spa_4K7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MFM970aOgev-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f7e0b3-fd39-4aa9-c293-035ec449fed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12163/12163 [==============================] - 35s 3ms/step\n",
            "Accuracy: 0.09\n",
            "Precision: 0.02\n",
            "Recall: 0.14\n",
            "F1 Score: 0.04\n"
          ]
        }
      ],
      "source": [
        "cicids_test = tf.convert_to_tensor(cicids_test)\n",
        "cicids_lables = tf.reshape(cicids_lables_test, (cicids_lables_test.shape[0], 1))\n",
        "c_adv_x = create_adversarial_examples(cicids_test, cicids_lables, cicids_model) + cicids_test\n",
        "c_adv_preds = make_predictions(cicids_model, c_adv_x, cicids_lables_test)\n",
        "calculate_metrics(cicids_lables_test, c_adv_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNSW"
      ],
      "metadata": {
        "id": "VYq22j254J6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the test set and labels to tensors\n",
        "unsw_test = tf.convert_to_tensor(unsw_test)\n",
        "unsw_labels = tf.reshape(unsw_lables_test, (unsw_lables_test.shape[0], 1))\n",
        "\n",
        "# Create adversarial examples\n",
        "u_adv_x = create_adversarial_examples(unsw_test, unsw_labels, unsw_model) + unsw_test\n",
        "\n",
        "# Predict on the adversarial examples\n",
        "u_adv_preds = make_predictions(unsw_model, u_adv_x, unsw_lables_test)\n",
        "calculate_metrics(unsw_lables_test, u_adv_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4KaQeAz4Mxw",
        "outputId": "e062833d-ea06-4f9d-8ef9-f9fc05527739"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1370/1370 [==============================] - 4s 3ms/step\n",
            "Accuracy: 0.15\n",
            "Precision: 0.18\n",
            "Recall: 0.07\n",
            "F1 Score: 0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing Things"
      ],
      "metadata": {
        "id": "rCc5TmxThswJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AscB0m7Xlvuh",
        "outputId": "3b8ab51c-2f4b-42c8-8f9c-4627d89c7c62"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fig. 1, the summarization of the LSTM Model Trained on the UNSW Dataset\")\n",
        "print(unsw_model.summary())\n",
        "print(\"Fig. 2, the summarization of the LSTM Model Trained on the CICIDS Dataset\")\n",
        "print(cicids_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3nWRaqflcb4",
        "outputId": "09b909cb-ca38-4be6-9b4c-a9ec362dbf1a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fig. 1, the summarization of the LSTM Model Trained on the UNSW Dataset\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 1, 256)            322560    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 256)            0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 523841 (2.00 MB)\n",
            "Trainable params: 523841 (2.00 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Fig. 2, the summarization of the LSTM Model Trained on the CICIDS Dataset\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 1, 256)            340992    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 256)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               197120    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 542273 (2.07 MB)\n",
            "Trainable params: 542273 (2.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(cicids_model, to_file='cicids_model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "vqgE-cdRlinM",
        "outputId": "524a124b-cf7f-47c5-ff42-56fce56a65dd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-be79d6abec20>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcicids_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cicids_model_plot.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cm(labels, preds, title):\n",
        "  conf_matrix = confusion_matrix(labels, preds)\n",
        "\n",
        "# Step 5: Plot the confusion matrix using seaborn for better visualization\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "  plt.xlabel('Predicted Labels')\n",
        "  plt.ylabel('True Labels')\n",
        "  plt.title(title)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "l3Z4pgV2hvVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(cicids_lables_test))\n",
        "print(len(clean_preds))\n",
        "print(len(unsw_lables_test))\n",
        "print(len(unsw_clean_preds))\n",
        "print(len(c_adv_preds))\n",
        "print(len(u_adv_preds))"
      ],
      "metadata": {
        "id": "iVOrzMz1jRav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_preds = clean_preds.flatten()\n",
        "flat_unsw_preds = unsw_clean_preds.flatten()\n",
        "flat_c_adv_preds = c_adv_preds.flatten()\n",
        "flat_u_adv_preds = u_adv_preds.flatten()\n",
        "print(flat_preds.shape)\n",
        "print(flat_unsw_preds.shape)\n",
        "print(flat_c_adv_preds.shape)\n",
        "print(flat_u_adv_preds.shape)"
      ],
      "metadata": {
        "id": "gnvCF5YdjxWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cicids_lables_test.shape)\n",
        "print(flat_preds.shape)\n",
        "print(unsw_lables_test.shape)\n",
        "print(unsw_clean_preds.shape)\n",
        "print(c_adv_preds.shape)\n",
        "print(u_adv_preds.shape)"
      ],
      "metadata": {
        "id": "thQACTO4jfuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_lables = np.where(cicids_lables_test >= 0.5, 1, 0)\n",
        "binary_unsw_lables = np.where(unsw_lables_test >= 0.5, 1, 0)\n",
        "flat_lables = binary_lables.flatten()\n",
        "flat_unsw_lables = binary_unsw_lables.flatten()"
      ],
      "metadata": {
        "id": "X8-3Xg06kdr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(flat_lables, flat_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted Negative', 'Predicted Positive'], yticklabels=['Actual Negative', 'Actual Positive'])\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('CICIDS Clean Predictions')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vxAiBt2XiYoY",
        "outputId": "3d5b899f-3844-4d22-e98c-10eb2c304bc8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Must pass 2-d input. shape=()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-992b8222d408>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_lables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Blues'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted Negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Predicted Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myticklabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual Negative'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Actual Positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted Labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'True Labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \"\"\"\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m# Initialize the plotter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0m\u001b[1;32m    447\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                           yticklabels, mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mplot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Validate the mask and convert to DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    756\u001b[0m                 )\n\u001b[1;32m    757\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                 mgr = ndarray_to_mgr(\n\u001b[0m\u001b[1;32m    759\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                     \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    313\u001b[0m         )\n\u001b[1;32m    314\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_ensure_2d\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Must pass 2-d input. shape={values.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must pass 2-d input. shape=()"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}